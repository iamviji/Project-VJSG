{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasMultiL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPz7mBCEE9+CICCNTa+rPCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/Project-VJSG/blob/master/PostMidTerm/Experiment/KerasMultiL_100_200_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dLvr1Rr1K8"
      },
      "source": [
        "import numpy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()\n",
        "\n",
        "input_message_length = 100\n",
        "encoder_output_length = 200\n",
        "channel_size = 100\n",
        "NUM_OF_INPUT_MESSAGE = 10000\n",
        "SNR_STEP_SIZE = .5\n",
        "\n",
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "\n",
        "bler_per_iter_uncoded_commpy_psk_2= [0.521, 0.473, 0.436, 0.37,  0.304, 0.259, 0.187, 0.138, 0.098, 0.098, 0.052, 0.028, 0.012, 0.011, 0.009, 0.002, 0.0,  0.001, 0.,    0.0]\n",
        "bler_per_iter_uncoded_itpp_psk_2= [0.518, 0.478, 0.415, 0.355, 0.305, 0.227, 0.177, 0.149, 0.11,  0.075, 0.055, 0.023, 0.014, 0.014, 0.015, 0.001, 0.003, 0.001, 0.,    0. ]\n",
        "bler_per_iter_uncoded_commpy_psk_4 = [0.815, 0.793, 0.75,  0.714, 0.64,  0.639, 0.526, 0.49,  0.433, 0.371, 0.335, 0.236, 0.204, 0.154, 0.129, 0.08,  0.063, 0.046, 0.023, 0.018]\n",
        "bler_per_iter_uncoded_itpp_psk_4 = [0.814, 0.767, 0.729, 0.702, 0.66,  0.616, 0.563, 0.511, 0.442, 0.4,   0.294, 0.277, 0.228, 0.17,  0.114, 0.087, 0.05,  0.037, 0.022, 0.017]\n",
        "bler_per_iter_ldpc_itpp_psk_4 = [0.584, 0.488, 0.404, 0.332, 0.218, 0.151, 0.097, 0.058, 0.041, 0.024, 0.007, 0.004, 0.002, 0.001, 0.001, 0.,    0.,    0.,    0.,    0.,   ]\n",
        "bler_per_iter_ham_itpp_psk_4= [0.51, 0.479, 0.419, 0.333, 0.313, 0.247, 0.212, 0.132, 0.114, 0.093, 0.042, 0.027, 0.024, 0.016, 0.006, 0.005, 0.003, 0.002, 0.,    0.  ]\n",
        "\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "\n",
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIqZA3RCrJgd",
        "outputId": "c43c6e4a-6150-48c1-9ec9-f10b28100ff4"
      },
      "source": [
        "\n",
        "awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [2*channel_size])\n",
        "awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "\n",
        "decoder_input_x = tf.placeholder(\"float32\", [None, input_message_length], name=\"decoder_input_x\")\n",
        "\n",
        "snr_std = 7.0\n",
        "\n",
        "input_message_x = Input(shape=(input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(encoder_output_length, activation='tanh')(input_message_x)\n",
        "enc_layer2 = Dense(2*channel_size, activation='tanh')(enc_layer1)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(2*channel_size,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(2*channel_size,))\n",
        "dec_layer1 = Dense(encoder_output_length, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(input_message_length, activation='sigmoid')(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "decoder_output = (tf.nn.sigmoid(decoder_input_x))\n",
        "\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_487\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 200)          20200       input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 200)          40200       dense_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_14 (TensorFl multiple             0           dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_14 (TensorFlow multiple             0           tf_op_layer_Square_14[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt_14 (TensorFlow multiple             0           tf_op_layer_Mean_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv_14 (TensorF multiple             0           dense_58[0][0]                   \n",
            "                                                                 tf_op_layer_Sqrt_14[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 60,400\n",
            "Trainable params: 60,400\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_489\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 100)               20100     \n",
            "=================================================================\n",
            "Total params: 60,300\n",
            "Trainable params: 60,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_491\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "functional_487 (Functional)  (None, 200)               60400     \n",
            "_________________________________________________________________\n",
            "gaussian_noise_216 (Gaussian (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "functional_489 (Functional)  (None, 100)               60300     \n",
            "=================================================================\n",
            "Total params: 120,700\n",
            "Trainable params: 120,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IidQMKlts65l",
        "outputId": "bc62304e-571f-4763-abc8-c3e41df120f6"
      },
      "source": [
        "training_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))\n",
        "print(input_message_length)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 ... 1 0 1]\n",
            " [1 1 0 ... 1 1 1]\n",
            " [0 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 0 0 ... 1 1 1]\n",
            " [1 0 1 ... 1 1 1]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "100000\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORw0oaAjsrXG",
        "outputId": "d45bcdde-b20c-4c2f-8d91-1d19cfeb9606"
      },
      "source": [
        "test_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (test_input_message)\n",
        "print (len(test_input_message))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 0 ... 0 1 0]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 0 0 ... 0 1 1]\n",
            " ...\n",
            " [0 0 0 ... 0 1 1]\n",
            " [0 1 0 ... 1 0 0]\n",
            " [1 0 1 ... 0 1 0]]\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbiBvRFNtUly",
        "outputId": "0d920bfc-86fb-48b7-eb4b-3ba179593ceb"
      },
      "source": [
        "import keras\n",
        "\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "  autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  autoencoder.fit(training_input_message, training_input_message,\n",
        "                #epochs=50, original\n",
        "                epochs=25,\n",
        "                batch_size=500,\n",
        "                shuffle=False,\n",
        "                validation_data=(test_input_message, test_input_message))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3583 - val_loss: 0.0988\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2696 - val_loss: 0.0713\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2555 - val_loss: 0.0600\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2491 - val_loss: 0.0531\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2457 - val_loss: 0.0490\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 58us/sample - loss: 0.2436 - val_loss: 0.0465\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2420 - val_loss: 0.0444\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2404 - val_loss: 0.0427\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2394 - val_loss: 0.0418\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2388 - val_loss: 0.0405\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.2382 - val_loss: 0.0401\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.2376 - val_loss: 0.0398\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2373 - val_loss: 0.0393\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 58us/sample - loss: 0.2370 - val_loss: 0.0387\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2364 - val_loss: 0.0381\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2361 - val_loss: 0.0381\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2357 - val_loss: 0.0381\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2354 - val_loss: 0.0375\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2354 - val_loss: 0.0373\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2351 - val_loss: 0.0372\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2351 - val_loss: 0.0368\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2346 - val_loss: 0.0371\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2344 - val_loss: 0.0369\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2342 - val_loss: 0.0369\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2345 - val_loss: 0.0368\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 96us/sample - loss: 0.2113 - val_loss: 0.0305\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2095 - val_loss: 0.0286\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2063 - val_loss: 0.0262\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2055 - val_loss: 0.0255\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2048 - val_loss: 0.0252\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2051 - val_loss: 0.0249\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2048 - val_loss: 0.0243\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2049 - val_loss: 0.0245\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2047 - val_loss: 0.0240\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2047 - val_loss: 0.0242\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2048 - val_loss: 0.0245\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2044 - val_loss: 0.0240\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2047 - val_loss: 0.0237\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.2042 - val_loss: 0.0237\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.2047 - val_loss: 0.0236\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2043 - val_loss: 0.0237\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 58us/sample - loss: 0.2043 - val_loss: 0.0239\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2041 - val_loss: 0.0237\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2044 - val_loss: 0.0237\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2041 - val_loss: 0.0235\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2040 - val_loss: 0.0234\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2037 - val_loss: 0.0237\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2038 - val_loss: 0.0237\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.2036 - val_loss: 0.0235\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.2036 - val_loss: 0.0236\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 9s 95us/sample - loss: 0.1815 - val_loss: 0.0189\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.1799 - val_loss: 0.0187\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1798 - val_loss: 0.0183\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.1796 - val_loss: 0.0181\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1800 - val_loss: 0.0175\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1793 - val_loss: 0.0173\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1793 - val_loss: 0.0174\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1793 - val_loss: 0.0171\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1792 - val_loss: 0.0170\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.1788 - val_loss: 0.0169\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1788 - val_loss: 0.0167\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1786 - val_loss: 0.0167\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1785 - val_loss: 0.0167\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1782 - val_loss: 0.0164\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1781 - val_loss: 0.0165\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1777 - val_loss: 0.0163\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1780 - val_loss: 0.0162\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1773 - val_loss: 0.0161\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1773 - val_loss: 0.0159\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1770 - val_loss: 0.0159\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1765 - val_loss: 0.0158\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1761 - val_loss: 0.0156\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.1761 - val_loss: 0.0157\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1753 - val_loss: 0.0156\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1752 - val_loss: 0.0156\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 97us/sample - loss: 0.1546 - val_loss: 0.0125\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1525 - val_loss: 0.0120\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1520 - val_loss: 0.0116\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1517 - val_loss: 0.0113\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1511 - val_loss: 0.0110\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1503 - val_loss: 0.0108\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1492 - val_loss: 0.0102\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1483 - val_loss: 0.0099\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1469 - val_loss: 0.0094\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.1460 - val_loss: 0.0093\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.1450 - val_loss: 0.0090\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1438 - val_loss: 0.0088\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1426 - val_loss: 0.0085\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1415 - val_loss: 0.0082\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1409 - val_loss: 0.0081\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1400 - val_loss: 0.0080\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1392 - val_loss: 0.0078\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1384 - val_loss: 0.0077\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1379 - val_loss: 0.0077\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1371 - val_loss: 0.0076\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1363 - val_loss: 0.0076\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.1359 - val_loss: 0.0076\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.1353 - val_loss: 0.0077\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1345 - val_loss: 0.0077\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1342 - val_loss: 0.0078\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 97us/sample - loss: 0.1129 - val_loss: 0.0059\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1120 - val_loss: 0.0059\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1111 - val_loss: 0.0059\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1107 - val_loss: 0.0060\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1104 - val_loss: 0.0061\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1099 - val_loss: 0.0062\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.1096 - val_loss: 0.0064\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.1090 - val_loss: 0.0064\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1090 - val_loss: 0.0066\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.1088 - val_loss: 0.0067\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1144 - val_loss: 0.0348\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1108 - val_loss: 0.0072\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1082 - val_loss: 0.0071\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1080 - val_loss: 0.0071\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1081 - val_loss: 0.0071\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1083 - val_loss: 0.0072\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1083 - val_loss: 0.0073\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1080 - val_loss: 0.0073\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1079 - val_loss: 0.0073\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1079 - val_loss: 0.0073\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1081 - val_loss: 0.0074\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.1080 - val_loss: 0.0074\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1082 - val_loss: 0.0075\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1079 - val_loss: 0.0074\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.1210 - val_loss: 0.0090\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 97us/sample - loss: 0.0893 - val_loss: 0.0061\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0884 - val_loss: 0.0058\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0930 - val_loss: 0.0061\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0878 - val_loss: 0.0058\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0881 - val_loss: 0.0057\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0877 - val_loss: 0.0057\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0878 - val_loss: 0.0056\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0879 - val_loss: 0.0057\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0879 - val_loss: 0.0056\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0879 - val_loss: 0.0056\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0879 - val_loss: 0.0056\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0878 - val_loss: 0.0056\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.1049 - val_loss: 0.0065\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0888 - val_loss: 0.0060\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0882 - val_loss: 0.0058\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0879 - val_loss: 0.0057\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0881 - val_loss: 0.0057\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0876 - val_loss: 0.0056\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0876 - val_loss: 0.0056\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0877 - val_loss: 0.0056\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0876 - val_loss: 0.0056\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0878 - val_loss: 0.0055\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0877 - val_loss: 0.0056\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0876 - val_loss: 0.0055\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0877 - val_loss: 0.0056\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 95us/sample - loss: 0.0702 - val_loss: 0.0042\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0747 - val_loss: 0.0042\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0699 - val_loss: 0.0042\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0695 - val_loss: 0.0041\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0824 - val_loss: 0.0046\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0697 - val_loss: 0.0043\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0699 - val_loss: 0.0043\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0698 - val_loss: 0.0042\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0698 - val_loss: 0.0042\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0694 - val_loss: 0.0041\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0696 - val_loss: 0.0041\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0698 - val_loss: 0.0041\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0698 - val_loss: 0.0041\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0695 - val_loss: 0.0041\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0699 - val_loss: 0.0041\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0697 - val_loss: 0.0041\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0897 - val_loss: 0.0541\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0751 - val_loss: 0.0048\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 97us/sample - loss: 0.0554 - val_loss: 0.0034\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0546 - val_loss: 0.0032\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0627 - val_loss: 0.0039\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0551 - val_loss: 0.0032\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0545 - val_loss: 0.0032\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0543 - val_loss: 0.0031\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0542 - val_loss: 0.0031\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0545 - val_loss: 0.0031\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0541 - val_loss: 0.0031\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0541 - val_loss: 0.0030\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0756 - val_loss: 0.0037\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0553 - val_loss: 0.0034\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0544 - val_loss: 0.0033\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 58us/sample - loss: 0.0542 - val_loss: 0.0032\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0542 - val_loss: 0.0032\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0542 - val_loss: 0.0031\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0542 - val_loss: 0.0031\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0542 - val_loss: 0.0031\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0543 - val_loss: 0.0031\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0543 - val_loss: 0.0031\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0543 - val_loss: 0.0031\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0541 - val_loss: 0.0031\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0543 - val_loss: 0.0031\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0541 - val_loss: 0.0030\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0542 - val_loss: 0.0031\n",
            "Training for SNR= 4.0  sigma= 0.6309573444801932\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 100us/sample - loss: 0.0471 - val_loss: 0.0024\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0413 - val_loss: 0.0023\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0597 - val_loss: 0.0030\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0440 - val_loss: 0.0025\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0418 - val_loss: 0.0024\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0413 - val_loss: 0.0024\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0412 - val_loss: 0.0023\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0411 - val_loss: 0.0023\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0409 - val_loss: 0.0023\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0410 - val_loss: 0.0023\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0409 - val_loss: 0.0023\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0410 - val_loss: 0.0023\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0409 - val_loss: 0.0023\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0706 - val_loss: 0.0034\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0430 - val_loss: 0.0028\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0417 - val_loss: 0.0026\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0415 - val_loss: 0.0025\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0412 - val_loss: 0.0024\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0408 - val_loss: 0.0024\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0411 - val_loss: 0.0024\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0410 - val_loss: 0.0023\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0411 - val_loss: 0.0023\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0411 - val_loss: 0.0023\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0411 - val_loss: 0.0023\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0412 - val_loss: 0.0023\n",
            "Training for SNR= 4.5  sigma= 0.5956621435290105\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 102us/sample - loss: 0.0304 - val_loss: 0.0018\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0421 - val_loss: 0.0019\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0310 - val_loss: 0.0018\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0307 - val_loss: 0.0017\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0304 - val_loss: 0.0017\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0302 - val_loss: 0.0017\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0303 - val_loss: 0.0018\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0447 - val_loss: 0.0020\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0304 - val_loss: 0.0019\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0304 - val_loss: 0.0018\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0303 - val_loss: 0.0018\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0302 - val_loss: 0.0018\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0304 - val_loss: 0.0018\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0304 - val_loss: 0.0018\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0303 - val_loss: 0.0017\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0303 - val_loss: 0.0017\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0303 - val_loss: 0.0017\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0304 - val_loss: 0.0017\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0305 - val_loss: 0.0017\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0305 - val_loss: 0.0017\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0305 - val_loss: 0.0017\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0509 - val_loss: 0.0022\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0309 - val_loss: 0.0020\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0305 - val_loss: 0.0019\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0306 - val_loss: 0.0018\n",
            "Training for SNR= 5.0  sigma= 0.5623413251903491\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 99us/sample - loss: 0.0277 - val_loss: 0.0015\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 9s 92us/sample - loss: 0.0316 - val_loss: 0.0015\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0220 - val_loss: 0.0013\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0219 - val_loss: 0.0013\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0219 - val_loss: 0.0013\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0406 - val_loss: 0.0018\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0230 - val_loss: 0.0015\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0222 - val_loss: 0.0014\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0220 - val_loss: 0.0014\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0218 - val_loss: 0.0013\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0218 - val_loss: 0.0013\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0219 - val_loss: 0.0013\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0217 - val_loss: 0.0013\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0218 - val_loss: 0.0013\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0219 - val_loss: 0.0013\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 59us/sample - loss: 0.0218 - val_loss: 0.0013\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0407 - val_loss: 0.0016\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0224 - val_loss: 0.0015\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0220 - val_loss: 0.0014\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 8s 85us/sample - loss: 0.0218 - val_loss: 0.0014\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0220 - val_loss: 0.0014\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0219 - val_loss: 0.0014\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0218 - val_loss: 0.0013\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0217 - val_loss: 0.0013\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0219 - val_loss: 0.0013\n",
            "Training for SNR= 5.5  sigma= 0.5308844442309884\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 98us/sample - loss: 0.0157 - val_loss: 0.0011\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0231 - val_loss: 0.0013\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 60us/sample - loss: 0.0209 - val_loss: 0.0011\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0156 - val_loss: 0.0011\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0191 - val_loss: 0.0134\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0216 - val_loss: 0.0012\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0157 - val_loss: 0.0010\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0187 - val_loss: 0.0022\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0163 - val_loss: 0.0010\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0156 - val_loss: 0.0010\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0159 - val_loss: 0.0020\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0269 - val_loss: 0.0012\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0158 - val_loss: 0.0011\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0160 - val_loss: 0.0137\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0156 - val_loss: 0.0011\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0197 - val_loss: 0.0018\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0162 - val_loss: 0.0013\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0157 - val_loss: 0.0024\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0165 - val_loss: 0.0012\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0159 - val_loss: 0.0012\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0165 - val_loss: 0.0012\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0157 - val_loss: 0.0011\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0156 - val_loss: 0.0012\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0158 - val_loss: 0.0014\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0160 - val_loss: 0.0019\n",
            "Training for SNR= 6.0  sigma= 0.5011872336272722\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 100us/sample - loss: 0.0110 - val_loss: 0.0011\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0111 - val_loss: 9.5234e-04\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0107 - val_loss: 0.0017\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0113 - val_loss: 0.0011\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0113 - val_loss: 0.0053\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0115 - val_loss: 0.0013\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0109 - val_loss: 9.1565e-04\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0110 - val_loss: 0.0011\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0110 - val_loss: 0.0010\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0117 - val_loss: 0.0013\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0116 - val_loss: 0.0017\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0113 - val_loss: 0.0010\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0113 - val_loss: 0.0014\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0114 - val_loss: 0.0014\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0114 - val_loss: 0.0010\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0113 - val_loss: 0.0013\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0115 - val_loss: 0.0024\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0114 - val_loss: 0.0013\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0114 - val_loss: 0.0016\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0116 - val_loss: 0.0014\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0125 - val_loss: 0.0020\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0117 - val_loss: 0.0015\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0111 - val_loss: 0.0012\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0114 - val_loss: 0.0014\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0118 - val_loss: 0.0017\n",
            "Training for SNR= 6.5  sigma= 0.47315125896148047\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 99us/sample - loss: 0.0077 - val_loss: 0.0015\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0081 - val_loss: 0.0016\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0077 - val_loss: 0.0013\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0081 - val_loss: 0.0019\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0083 - val_loss: 0.0014\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0084 - val_loss: 0.0016\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0079 - val_loss: 0.0014\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0082 - val_loss: 0.0022\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0083 - val_loss: 0.0019\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0082 - val_loss: 0.0013\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0084 - val_loss: 0.0019\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0083 - val_loss: 0.0016\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0080 - val_loss: 0.0023\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0086 - val_loss: 0.0020\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0084 - val_loss: 0.0021\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0081 - val_loss: 0.0022\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 7s 67us/sample - loss: 0.0081 - val_loss: 0.0015\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 7s 65us/sample - loss: 0.0086 - val_loss: 0.0023\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0088 - val_loss: 0.0030\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0088 - val_loss: 0.0019\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0085 - val_loss: 0.0024\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0087 - val_loss: 0.0020\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0086 - val_loss: 0.0024\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0084 - val_loss: 0.0023\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 61us/sample - loss: 0.0088 - val_loss: 0.0019\n",
            "Training for SNR= 7.0  sigma= 0.44668359215096315\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 101us/sample - loss: 0.0059 - val_loss: 0.0016\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0062 - val_loss: 0.0023\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0062 - val_loss: 0.0019\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0064 - val_loss: 0.0030\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0063 - val_loss: 0.0023\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0060 - val_loss: 0.0027\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0065 - val_loss: 0.0029\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0063 - val_loss: 0.0016\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0063 - val_loss: 0.0023\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0063 - val_loss: 0.0029\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0065 - val_loss: 0.0017\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0060 - val_loss: 0.0020\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0066 - val_loss: 0.0026\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0066 - val_loss: 0.0021\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0065 - val_loss: 0.0026\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0067 - val_loss: 0.0028\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0065 - val_loss: 0.0020\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0068 - val_loss: 0.0021\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0067 - val_loss: 0.0026\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0065 - val_loss: 0.0026\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0066 - val_loss: 0.0030\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0066 - val_loss: 0.0030\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0068 - val_loss: 0.0026\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0069 - val_loss: 0.0032\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0070 - val_loss: 0.0024\n",
            "Training for SNR= 7.5  sigma= 0.4216965034285822\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 100us/sample - loss: 0.0050 - val_loss: 0.0025\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0047 - val_loss: 0.0030\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0050 - val_loss: 0.0019\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0050 - val_loss: 0.0029\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0054 - val_loss: 0.0029\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0052 - val_loss: 0.0029\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0056 - val_loss: 0.0022\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0052 - val_loss: 0.0026\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0053 - val_loss: 0.0032\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0051 - val_loss: 0.0027\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0054 - val_loss: 0.0034\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0054 - val_loss: 0.0024\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0056 - val_loss: 0.0049\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0056 - val_loss: 0.0035\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0050 - val_loss: 0.0041\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0055 - val_loss: 0.0029\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0058 - val_loss: 0.0029\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0057 - val_loss: 0.0027\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0054 - val_loss: 0.0029\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0054 - val_loss: 0.0051\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0062 - val_loss: 0.0031\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0062 - val_loss: 0.0044\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0058 - val_loss: 0.0037\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0061 - val_loss: 0.0036\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0057 - val_loss: 0.0029\n",
            "Training for SNR= 8.0  sigma= 0.3981071705534972\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 101us/sample - loss: 0.0045 - val_loss: 0.0040\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0050 - val_loss: 0.0040\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0045 - val_loss: 0.0037\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0046 - val_loss: 0.0047\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0052 - val_loss: 0.0078\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0055 - val_loss: 0.0036\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0046 - val_loss: 0.0039\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0047 - val_loss: 0.0030\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0049 - val_loss: 0.0055\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0056 - val_loss: 0.0034\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0052 - val_loss: 0.0055\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0051 - val_loss: 0.0041\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0054 - val_loss: 0.0038\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0045 - val_loss: 0.0042\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0056 - val_loss: 0.0040\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0048 - val_loss: 0.0039\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0054 - val_loss: 0.0049\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0059 - val_loss: 0.0035\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0054 - val_loss: 0.0036\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0051 - val_loss: 0.0037\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0056 - val_loss: 0.0044\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0055 - val_loss: 0.0035\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0053 - val_loss: 0.0047\n",
            "Training for SNR= 8.5  sigma= 0.3758374042884442\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 102us/sample - loss: 0.0045 - val_loss: 0.0050\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0048 - val_loss: 0.0032\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0048 - val_loss: 0.0046\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0047 - val_loss: 0.0039\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0054 - val_loss: 0.0046\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0042 - val_loss: 0.0039\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0048 - val_loss: 0.0037\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 7s 67us/sample - loss: 0.0052 - val_loss: 0.0043\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0051 - val_loss: 0.0045\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0052 - val_loss: 0.0076\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0054 - val_loss: 0.0047\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0053 - val_loss: 0.0038\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0050 - val_loss: 0.0055\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0045 - val_loss: 0.0036\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0049 - val_loss: 0.0052\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0056 - val_loss: 0.0046\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0058 - val_loss: 0.0058\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0053 - val_loss: 0.0051\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0047 - val_loss: 0.0043\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0053 - val_loss: 0.0045\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0053 - val_loss: 0.0042\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0058 - val_loss: 0.0057\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0055 - val_loss: 0.0055\n",
            "Training for SNR= 9.0  sigma= 0.35481338923357547\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 103us/sample - loss: 0.0049 - val_loss: 0.0061\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0053 - val_loss: 0.0065\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0053 - val_loss: 0.0065\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0052 - val_loss: 0.0056\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0046 - val_loss: 0.0039\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0046 - val_loss: 0.0054\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0055 - val_loss: 0.0046\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0053 - val_loss: 0.0042\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0055 - val_loss: 0.0064\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0055 - val_loss: 0.0072\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0056 - val_loss: 0.0063\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0059 - val_loss: 0.0058\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0052 - val_loss: 0.0071\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0051 - val_loss: 0.0065\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0057 - val_loss: 0.0047\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0059 - val_loss: 0.0058\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0056 - val_loss: 0.0069\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0056 - val_loss: 0.0045\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0051 - val_loss: 0.0056\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 6s 62us/sample - loss: 0.0057 - val_loss: 0.0042\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0058 - val_loss: 0.0065\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0058 - val_loss: 0.0060\n",
            "Training for SNR= 9.5  sigma= 0.33496543915782767\n",
            "Train on 100000 samples, validate on 100000 samples\n",
            "Epoch 1/25\n",
            "100000/100000 [==============================] - 10s 101us/sample - loss: 0.0056 - val_loss: 0.0054\n",
            "Epoch 2/25\n",
            "100000/100000 [==============================] - 7s 67us/sample - loss: 0.0053 - val_loss: 0.0051\n",
            "Epoch 3/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 4/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0057 - val_loss: 0.0097\n",
            "Epoch 5/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0059 - val_loss: 0.0079\n",
            "Epoch 6/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 7/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0051 - val_loss: 0.0060\n",
            "Epoch 8/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0062 - val_loss: 0.0052\n",
            "Epoch 9/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0061 - val_loss: 0.0062\n",
            "Epoch 10/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0062 - val_loss: 0.0067\n",
            "Epoch 11/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0051 - val_loss: 0.0064\n",
            "Epoch 12/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 13/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0059 - val_loss: 0.0069\n",
            "Epoch 14/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0061 - val_loss: 0.0126\n",
            "Epoch 15/25\n",
            "100000/100000 [==============================] - 6s 63us/sample - loss: 0.0058 - val_loss: 0.0077\n",
            "Epoch 16/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0054 - val_loss: 0.0054\n",
            "Epoch 17/25\n",
            "100000/100000 [==============================] - 6s 65us/sample - loss: 0.0056 - val_loss: 0.0083\n",
            "Epoch 18/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0066 - val_loss: 0.0052\n",
            "Epoch 19/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0062 - val_loss: 0.0079\n",
            "Epoch 20/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0051 - val_loss: 0.0052\n",
            "Epoch 21/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0052 - val_loss: 0.0049\n",
            "Epoch 22/25\n",
            "100000/100000 [==============================] - 7s 66us/sample - loss: 0.0062 - val_loss: 0.0060\n",
            "Epoch 23/25\n",
            "100000/100000 [==============================] - 7s 67us/sample - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 24/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0059 - val_loss: 0.0064\n",
            "Epoch 25/25\n",
            "100000/100000 [==============================] - 6s 64us/sample - loss: 0.0059 - val_loss: 0.0052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjVpOnoOuF0o"
      },
      "source": [
        "\n",
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(channel_size,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [channel_size])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "train_init = tf.global_variables_initializer ()\n",
        "train_sess = tf.Session ()\n",
        "\n",
        "channel_in = []\n",
        "channel_out = []\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = training_input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    channel_in.append(encoded_message[0])\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,2*channel_size])\n",
        "    channel_out.append(noised_message[0]) \n",
        "    #noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,channel_size])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-training_input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cALSMP2YvKvC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(100-200-100)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f941H6lZvxF6"
      },
      "source": [
        "\n",
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(channel_size,))\n",
        "\n",
        "\n",
        "train_init = tf.global_variables_initializer ()\n",
        "train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = test_input_message [i:i+1]\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,2*channel_size])\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    if abs(decoded_message-test_input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkx6sASfv9Uk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(100-200-100\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnVP37k_BSJp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "channel_in_array = numpy.transpose(channel_in)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.scatter(channel_in_array[i*2], channel_in_array[i*2+1])\n",
        "  plt.show()\n",
        "  plt.hist2d(channel_in_array[i*2], channel_in_array[i*2+1], cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beBR7QoLBUr-"
      },
      "source": [
        "channel_out_array = numpy.transpose(channel_out)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.hist2d(channel_out_array[2*i], channel_out_array[2*i+1], (50, 50), cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}